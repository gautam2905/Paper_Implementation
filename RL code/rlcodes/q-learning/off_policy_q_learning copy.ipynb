{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e5445b",
   "metadata": {},
   "source": [
    "# Deep Q-Learning Algorithm \n",
    "\n",
    "Simple Q-learning is basic and is all about learning state action value for all possible "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a66b5c",
   "metadata": {},
   "source": [
    "### Algorithm \n",
    "![alt text](sampling-training.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe16ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "645f6624",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, hidden_units, state_size, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.input_dim = state_size\n",
    "        self.output_dim = action_size\n",
    "\n",
    "        self.q_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        return self.q_netwrok(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d53842",
   "metadata": {},
   "outputs": [
    {
     "ename": "NamespaceNotFound",
     "evalue": "Namespace ALE not found. Have you installed the proper package for ALE?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNamespaceNotFound\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# env = gym.make(\"CartPole-v1\", new_step_api=True)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mALE/Breakout-v5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m state_size \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m action_size \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\gymnasium\\envs\\registration.py:689\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, max_episode_steps, disable_env_checker, **kwargs)\u001b[0m\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mid\u001b[39m, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;66;03m# The environment name can include an unloaded module in \"module:env_name\" style\u001b[39;00m\n\u001b[1;32m--> 689\u001b[0m     env_spec \u001b[38;5;241m=\u001b[39m \u001b[43m_find_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(env_spec, EnvSpec)\n\u001b[0;32m    693\u001b[0m \u001b[38;5;66;03m# Update the env spec kwargs with the `make` kwargs\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\gymnasium\\envs\\registration.py:533\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(env_id)\u001b[0m\n\u001b[0;32m    527\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    528\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the latest versioned environment `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_env_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    529\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead of the unversioned environment `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    530\u001b[0m     )\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m env_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 533\u001b[0m     \u001b[43m_check_version_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mError(\n\u001b[0;32m    535\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo registered env with id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Did you register it, or import the package that registers it? Use `gymnasium.pprint_registry()` to see all of the registered environments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    536\u001b[0m     )\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m env_spec\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\gymnasium\\envs\\registration.py:399\u001b[0m, in \u001b[0;36m_check_version_exists\u001b[1;34m(ns, name, version)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_env_id(ns, name, version) \u001b[38;5;129;01min\u001b[39;00m registry:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m \u001b[43m_check_name_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\gymnasium\\envs\\registration.py:362\u001b[0m, in \u001b[0;36m_check_name_exists\u001b[1;34m(ns, name)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check if an env exists in a namespace. If it doesn't, print a helpful error message.\"\"\"\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;66;03m# First check if the namespace exists\u001b[39;00m\n\u001b[1;32m--> 362\u001b[0m \u001b[43m_check_namespace_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;66;03m# Then check if the name exists\u001b[39;00m\n\u001b[0;32m    365\u001b[0m names: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    366\u001b[0m     env_spec\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m env_spec \u001b[38;5;129;01min\u001b[39;00m registry\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m env_spec\u001b[38;5;241m.\u001b[39mnamespace \u001b[38;5;241m==\u001b[39m ns\n\u001b[0;32m    367\u001b[0m }\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\gymnasium\\envs\\registration.py:356\u001b[0m, in \u001b[0;36m_check_namespace_exists\u001b[1;34m(ns)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    354\u001b[0m     suggestion_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHave you installed the proper package for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 356\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mNamespaceNotFound(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNamespace \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestion_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNamespaceNotFound\u001b[0m: Namespace ALE not found. Have you installed the proper package for ALE?"
     ]
    }
   ],
   "source": [
    "# env = gym.make(\"CartPole-v1\", new_step_api=True)\n",
    "import gymnasium as gym\n",
    "env = gym.make('ALE/Breakout-v5')\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space\n",
    "action_size = 6\n",
    "# Hyperparameters\n",
    "gamma = 0.99             \n",
    "epsilon = 1.0           \n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "memory_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32d5769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall gym atari_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a6eae2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium[atari] in c:\\users\\gupta\\appdata\\roaming\\python\\python310\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python310\\site-packages (from gymnasium[atari]) (1.24.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python310\\site-packages (from gymnasium[atari]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\gupta\\appdata\\roaming\\python\\python310\\site-packages (from gymnasium[atari]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\gupta\\appdata\\roaming\\python\\python310\\site-packages (from gymnasium[atari]) (0.0.4)\n",
      "Collecting ale_py>=0.9 (from gymnasium[atari])\n",
      "  Downloading ale_py-0.11.1-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Downloading ale_py-0.11.1-cp310-cp310-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/3.5 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.6/3.5 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 7.6 MB/s eta 0:00:00\n",
      "Installing collected packages: ale_py\n",
      "  Attempting uninstall: ale_py\n",
      "    Found existing installation: ale-py 0.7.5\n",
      "    Uninstalling ale-py-0.7.5:\n",
      "      Successfully uninstalled ale-py-0.7.5\n",
      "Successfully installed ale_py-0.11.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\gupta\\AppData\\Roaming\\Python\\Python310\\site-packages\\~le_py'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium[atari]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d7f704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = deque(maxlen=memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa15813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "target_network = DQN(24, state_size=state_size, action_size=action_size).to(device)\n",
    "q_network = DQN(24, state_size=state_size, action_size=action_size).to(device)\n",
    "target_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "target_network.eval()\n",
    "optimizer = optim.Adam(q_network.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37592491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_action(state, epsilon=epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return random.choice(range(action_size))\n",
    "    else:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            q_values = q_network(state)\n",
    "            \n",
    "        return q_values.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f4bb13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay():\n",
    "    if len(memory) < batch_size:\n",
    "        return \n",
    "    \n",
    "    minibatch = random.sample(memory, batch_size)\n",
    "\n",
    "    current_states, actions, rewards, next_states, dones = zip(*minibatch)\n",
    "\n",
    "    current_states = torch.FloatTensor(current_states).to(device=device)\n",
    "    actions = torch.LongTensor(actions).unsqueeze(1).to(device)\n",
    "    rewards = torch.FloatTensor(rewards).unsqueeze(1).to(device)\n",
    "    next_states = torch.FloatTensor(next_states).to(device)\n",
    "    dones = torch.FloatTensor(dones).unsqueeze(1).to(device)\n",
    "\n",
    "    current_q = q_network(current_states).gather(1, actions)\n",
    "\n",
    "    pred_q = target_network(next_states).max(1)[0].detach().unsqueeze(1)\n",
    "    target_q = rewards + (gamma * pred_q * (1 - dones))\n",
    "\n",
    "    loss = loss_fn(current_q, target_q) # current_q --> [64, 2]    target_q = [64, 1]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf7201ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Action dimension mismatch. Expected (6,), found ()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m500\u001b[39m):\n\u001b[0;32m     10\u001b[0m     action \u001b[38;5;241m=\u001b[39m epsilon_greedy_action(state, epsilon)\n\u001b[1;32m---> 11\u001b[0m     step_result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(step_result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[0;32m     13\u001b[0m         next_state, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m step_result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\gymnasium\\wrappers\\common.py:125\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[0;32m    114\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\gymnasium\\wrappers\\common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\gymnasium\\core.py:327\u001b[0m, in \u001b[0;36mWrapper.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[0;32m    325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\gymnasium\\wrappers\\common.py:283\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_step_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\gymnasium\\utils\\passive_env_checker.py:207\u001b[0m, in \u001b[0;36menv_step_passive_checker\u001b[1;34m(env, action)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# We don't check the action as for some environments then out-of-bounds values can be given\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    209\u001b[0m     result, \u001b[38;5;28mtuple\u001b[39m\n\u001b[0;32m    210\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpects step result to be a tuple, actual type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\gymnasium\\envs\\mujoco\\walker2d_v4.py:126\u001b[0m, in \u001b[0;36mWalker2dEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m    125\u001b[0m     x_position_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqpos[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe_skip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     x_position_after \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqpos[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    128\u001b[0m     x_velocity \u001b[38;5;241m=\u001b[39m (x_position_after \u001b[38;5;241m-\u001b[39m x_position_before) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\gymnasium\\envs\\mujoco\\mujoco_env.py:197\u001b[0m, in \u001b[0;36mMujocoEnv.do_simulation\u001b[1;34m(self, ctrl, n_frames)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# Check control input is contained in the action space\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(ctrl)\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnu,):\n\u001b[1;32m--> 197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction dimension mismatch. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnu,)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39marray(ctrl)\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m     )\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_mujoco_simulation(ctrl, n_frames)\n",
      "\u001b[1;31mValueError\u001b[0m: Action dimension mismatch. Expected (6,), found ()"
     ]
    }
   ],
   "source": [
    "episodes = 200\n",
    "target_update_freq = 1\n",
    "\n",
    "for episode in tqdm(range(episodes)):\n",
    "    reset_result = env.reset()\n",
    "    state = reset_result[0] if isinstance(reset_result, tuple) else reset_result\n",
    "    total_reward = 0\n",
    "\n",
    "    for t in range(500):\n",
    "        action = epsilon_greedy_action(state, epsilon)\n",
    "        step_result = env.step(action)\n",
    "        if len(step_result) == 5:\n",
    "            next_state, reward, terminated, truncated, _ = step_result\n",
    "            done = terminated or truncated\n",
    "        else:\n",
    "            next_state, reward, done, _ = step_result\n",
    "\n",
    "        memory.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "        replay()\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "    if episode % target_update_freq == 0:\n",
    "        target_network.load_state_dict(q_network.state_dict())\n",
    "    \n",
    "    if episode % 50 == 0:\n",
    "        print(f\"Episode {episode}, Total Reward: {total_reward}, Epsilon: {epsilon:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e0d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'q_network' is your model and training is finished\n",
    "import torch\n",
    "\n",
    "torch.save(q_network.state_dict(), 'q_network_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2472243d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Roaming\\Python\\Python310\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n",
      "C:\\Users\\gupta\\AppData\\Roaming\\Python\\Python310\\site-packages\\pkg_resources\\__init__.py:3146: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "C:\\Users\\gupta\\AppData\\Roaming\\Python\\Python310\\site-packages\\pkg_resources\\__init__.py:3146: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_8900\\3213432609.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Episode 1, Total Reward: 500.0\n",
      "Test Episode 2, Total Reward: 166.0\n",
      "Test Episode 3, Total Reward: 261.0\n",
      "Test Episode 4, Total Reward: 197.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m         total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;66;03m# Optional: Add a small delay to make the visualization easier to follow\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Episode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Total Reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_reward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m env\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# --- Assume your QNetwork and other necessary components are defined here ---\n",
    "# from your_model_file import QNetwork # Make sure to import your network architecture\n",
    "\n",
    "# --- Hyperparameters and Setup ---\n",
    "# Load the environment with rendering enabled\n",
    "env = gym.make('CartPole-v1', render_mode='human') # <-- IMPORTANT\n",
    "\n",
    "# Initialize your Q-network and load the trained weights\n",
    "# Ensure the state_size and action_size match your environment\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "q_network = DQN(24, state_size, action_size) # Your network class\n",
    "q_network.load_state_dict(torch.load('q_network_weights.pth'))\n",
    "q_network.eval() # Set the network to evaluation mode\n",
    "\n",
    "# --- The Greedy Action Function ---\n",
    "def greedy_action(state):\n",
    "    \"\"\"Chooses the best action based on the Q-network's prediction.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        q_values = q_network(state_tensor)\n",
    "        return np.argmax(q_values.cpu().data.numpy())\n",
    "\n",
    "# --- The Visual Testing Loop ---\n",
    "num_test_episodes = 10\n",
    "\n",
    "for episode in range(num_test_episodes):\n",
    "    reset_result = env.reset()\n",
    "    state = reset_result[0] if isinstance(reset_result, tuple) else reset_result\n",
    "    total_reward = 0\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "\n",
    "    while not (terminated or truncated):\n",
    "        # Render the environment\n",
    "        env.render()\n",
    "\n",
    "        # Agent chooses the best action (no epsilon)\n",
    "        action = greedy_action(state)\n",
    "\n",
    "        # Environment takes a step\n",
    "        step_result = env.step(action)\n",
    "\n",
    "        # Unpack the step result\n",
    "        if len(step_result) == 5:\n",
    "            next_state, reward, terminated, truncated, _ = step_result\n",
    "        else: # For older gym versions\n",
    "            next_state, reward, done, _ = step_result\n",
    "            terminated = done\n",
    "            truncated = done # Simplification for older API\n",
    "\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "        # Optional: Add a small delay to make the visualization easier to follow\n",
    "        time.sleep(0.02)\n",
    "\n",
    "    print(f\"Test Episode {episode + 1}, Total Reward: {total_reward}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb742071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.00681502,  0.03622616,  0.04379575,  0.03946735], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a0038a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c953f96f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
