{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9af5c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision.datasets import MNIST\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader \n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "Latent_noise_dim = 50 # (z) \n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "epochs = 100\n",
    "optimizer = optim.Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcbca91",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "77f66ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.) tensor(0.9922)\n"
     ]
    }
   ],
   "source": [
    "# Normalization: x -> (x - mean) / std\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # single channel, so one value\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=False\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "image, label = train_dataset[10]\n",
    "print(image.min(), image.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b09a77",
   "metadata": {},
   "source": [
    "## Prior On Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ebcb61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_z(z):\n",
    "    return torch.normal(0, 1, size=(z, Latent_noise_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25c8cb9",
   "metadata": {},
   "source": [
    "## Generator and Discriminator Network/function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8d6be66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.img_shape = img_shape\n",
    "        \n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            # *block(256, 512),\n",
    "            *block(256, 512),\n",
    "            nn.Linear(512, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "02ea33f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(D, real_imgs, fake_imgs):\n",
    "\n",
    "    real_preds = D(real_imgs)\n",
    "    fake_preds = D(fake_imgs)\n",
    "\n",
    "    eps = 1e-8\n",
    "    real_loss = -torch.mean(torch.log(real_preds + eps))\n",
    "    fake_loss = -torch.mean(torch.log(1 - fake_preds + eps))\n",
    "\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "\n",
    "def generator_loss(D, fake_imgs, non_saturating=True):\n",
    "    fake_preds = D(fake_imgs)\n",
    "    eps = 1e-8\n",
    "\n",
    "    if non_saturating:\n",
    "        g_loss = -torch.mean(torch.log(fake_preds + eps))\n",
    "    else:\n",
    "        g_loss = torch.mean(torch.log(1 - fake_preds + eps))\n",
    "\n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5dbd74",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1261592b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters in G: 574864\n",
      "Total parameters in D: 533505\n"
     ]
    }
   ],
   "source": [
    "D = Discriminator((1, 28, 28))\n",
    "G = Generator(Latent_noise_dim, (1, 28, 28))\n",
    "optimizer_D = optimizer(D.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "optimizer_G = optimizer(G.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "total_params = sum(p.numel() for p in G.parameters())\n",
    "total_params_D = sum(p.numel() for p in D.parameters())\n",
    "print(f\"Total parameters in G: {total_params}\")\n",
    "print(f\"Total parameters in D: {total_params_D}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b12c79a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_losses, g_losses = [], []\n",
    "\n",
    "# plt.ion()  # interactive mode\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     for i, (imgs, _) in enumerate(train_loader):\n",
    "        \n",
    "#         batch_size = imgs.size(0)\n",
    "#         real_imgs = imgs.type(torch.FloatTensor)\n",
    "        \n",
    "#         z = p_z(batch_size)\n",
    "#         fake_imgs = G(z).detach()   \n",
    "#         d_loss = discriminator_loss(D, real_imgs, fake_imgs)\n",
    "\n",
    "#         optimizer_D.zero_grad()\n",
    "#         d_loss.backward()\n",
    "#         optimizer_D.step()\n",
    "\n",
    "#         # --- Train G ---\n",
    "#         z = p_z(batch_size)\n",
    "#         fake_imgs = G(z)\n",
    "#         g_loss = generator_loss(D, fake_imgs, non_saturating=True)\n",
    "\n",
    "#         optimizer_G.zero_grad()\n",
    "#         g_loss.backward()\n",
    "#         optimizer_G.step()\n",
    "    \n",
    "#     # Save losses\n",
    "#     d_losses.append(d_loss.item())\n",
    "#     g_losses.append(g_loss.item())\n",
    "\n",
    "#     # Print losses\n",
    "#     print(f\"Epoch [{epoch+1}/{epochs}]  D_loss: {d_loss.item():.4f}  G_loss: {g_loss.item():.4f}\")\n",
    "\n",
    "#     # Update live plot\n",
    "#     # ax.clear()\n",
    "#     # ax.plot(d_losses, label=\"D loss\")\n",
    "#     # ax.plot(g_losses, label=\"G loss\")\n",
    "#     # ax.legend()\n",
    "#     # ax.set_xlabel(\"Epochs\")\n",
    "#     # ax.set_ylabel(\"Loss\")\n",
    "#     # plt.pause(0.01)\n",
    "\n",
    "#     # Save samples\n",
    "#     # if epoch % 100 == 0:\n",
    "#     save_image(fake_imgs.data[:25], f\"./images/{epoch}.png\", nrow=5, normalize=True)\n",
    "\n",
    "# # plt.ioff()\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(d_losses, label=\"D loss\")\n",
    "# plt.plot(g_losses, label=\"G loss\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ab61eeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]  D_loss: 0.7938  G_loss: 1.3375\n",
      "Epoch [2/100]  D_loss: 0.7299  G_loss: 1.8334\n",
      "Epoch [3/100]  D_loss: 0.6699  G_loss: 2.0184\n",
      "Epoch [4/100]  D_loss: 0.6427  G_loss: 2.1498\n",
      "Epoch [5/100]  D_loss: 0.6353  G_loss: 2.2568\n",
      "Epoch [6/100]  D_loss: 0.6127  G_loss: 2.3324\n",
      "Epoch [7/100]  D_loss: 0.6140  G_loss: 2.3782\n",
      "Epoch [8/100]  D_loss: 0.5638  G_loss: 2.4750\n",
      "Epoch [9/100]  D_loss: 0.5923  G_loss: 2.4516\n",
      "Epoch [10/100]  D_loss: 0.5277  G_loss: 2.6514\n",
      "Epoch [11/100]  D_loss: 0.5216  G_loss: 2.7197\n",
      "Epoch [12/100]  D_loss: 0.5600  G_loss: 2.6822\n",
      "Epoch [13/100]  D_loss: 0.5850  G_loss: 2.5306\n",
      "Epoch [14/100]  D_loss: 0.6041  G_loss: 2.3700\n",
      "Epoch [15/100]  D_loss: 0.6465  G_loss: 2.3291\n",
      "Epoch [16/100]  D_loss: 0.6342  G_loss: 2.2908\n",
      "Epoch [17/100]  D_loss: 0.6898  G_loss: 2.1911\n",
      "Epoch [18/100]  D_loss: 0.7554  G_loss: 1.9582\n",
      "Epoch [19/100]  D_loss: 0.7571  G_loss: 1.9175\n",
      "Epoch [20/100]  D_loss: 0.7765  G_loss: 1.8549\n",
      "Epoch [21/100]  D_loss: 0.8003  G_loss: 1.8154\n",
      "Epoch [22/100]  D_loss: 0.7805  G_loss: 1.8324\n",
      "Epoch [23/100]  D_loss: 0.8029  G_loss: 1.7944\n",
      "Epoch [24/100]  D_loss: 0.7900  G_loss: 1.8102\n",
      "Epoch [25/100]  D_loss: 0.7680  G_loss: 1.8258\n",
      "Epoch [26/100]  D_loss: 0.7881  G_loss: 1.8017\n",
      "Epoch [27/100]  D_loss: 0.7922  G_loss: 1.7857\n",
      "Epoch [28/100]  D_loss: 0.8132  G_loss: 1.7483\n",
      "Epoch [29/100]  D_loss: 0.7917  G_loss: 1.7500\n",
      "Epoch [30/100]  D_loss: 0.7850  G_loss: 1.7580\n",
      "Epoch [31/100]  D_loss: 0.8175  G_loss: 1.7407\n",
      "Epoch [32/100]  D_loss: 0.8083  G_loss: 1.7278\n",
      "Epoch [33/100]  D_loss: 0.7981  G_loss: 1.7356\n",
      "Epoch [34/100]  D_loss: 0.7898  G_loss: 1.7692\n",
      "Epoch [35/100]  D_loss: 0.7855  G_loss: 1.7668\n",
      "Epoch [36/100]  D_loss: 0.7793  G_loss: 1.7527\n",
      "Epoch [37/100]  D_loss: 0.7888  G_loss: 1.7565\n",
      "Epoch [38/100]  D_loss: 0.7823  G_loss: 1.7659\n",
      "Epoch [39/100]  D_loss: 0.7819  G_loss: 1.7745\n",
      "Epoch [40/100]  D_loss: 0.7856  G_loss: 1.7689\n",
      "Epoch [41/100]  D_loss: 0.7908  G_loss: 1.7190\n",
      "Epoch [42/100]  D_loss: 0.7846  G_loss: 1.7426\n",
      "Epoch [43/100]  D_loss: 0.7737  G_loss: 1.7544\n",
      "Epoch [44/100]  D_loss: 0.7831  G_loss: 1.7374\n",
      "Epoch [45/100]  D_loss: 0.7838  G_loss: 1.7392\n",
      "Epoch [46/100]  D_loss: 0.7725  G_loss: 1.7510\n",
      "Epoch [47/100]  D_loss: 0.7853  G_loss: 1.7392\n",
      "Epoch [48/100]  D_loss: 0.7884  G_loss: 1.7287\n",
      "Epoch [49/100]  D_loss: 0.7829  G_loss: 1.7333\n",
      "Epoch [50/100]  D_loss: 0.7761  G_loss: 1.7428\n",
      "Epoch [51/100]  D_loss: 0.7657  G_loss: 1.7708\n",
      "Epoch [52/100]  D_loss: 0.7670  G_loss: 1.7426\n",
      "Epoch [53/100]  D_loss: 0.7715  G_loss: 1.7414\n",
      "Epoch [54/100]  D_loss: 0.7719  G_loss: 1.7531\n",
      "Epoch [55/100]  D_loss: 0.7712  G_loss: 1.7575\n",
      "Epoch [56/100]  D_loss: 0.7775  G_loss: 1.7307\n",
      "Epoch [57/100]  D_loss: 0.7793  G_loss: 1.7471\n",
      "Epoch [58/100]  D_loss: 0.7699  G_loss: 1.7544\n",
      "Epoch [59/100]  D_loss: 0.7803  G_loss: 1.7297\n",
      "Epoch [60/100]  D_loss: 0.7678  G_loss: 1.7333\n",
      "Epoch [61/100]  D_loss: 0.7711  G_loss: 1.7308\n",
      "Epoch [62/100]  D_loss: 0.7811  G_loss: 1.7415\n",
      "Epoch [63/100]  D_loss: 0.7689  G_loss: 1.7282\n",
      "Epoch [64/100]  D_loss: 0.7787  G_loss: 1.7400\n",
      "Epoch [65/100]  D_loss: 0.7687  G_loss: 1.7335\n",
      "Epoch [66/100]  D_loss: 0.7662  G_loss: 1.7544\n",
      "Epoch [67/100]  D_loss: 0.7733  G_loss: 1.7125\n",
      "Epoch [68/100]  D_loss: 0.7810  G_loss: 1.7289\n",
      "Epoch [69/100]  D_loss: 0.7756  G_loss: 1.7239\n",
      "Epoch [70/100]  D_loss: 0.7715  G_loss: 1.7076\n",
      "Epoch [71/100]  D_loss: 0.7692  G_loss: 1.7329\n",
      "Epoch [72/100]  D_loss: 0.7672  G_loss: 1.7473\n",
      "Epoch [73/100]  D_loss: 0.7612  G_loss: 1.7400\n",
      "Epoch [74/100]  D_loss: 0.7635  G_loss: 1.7258\n",
      "Epoch [75/100]  D_loss: 0.7632  G_loss: 1.7375\n",
      "Epoch [76/100]  D_loss: 0.7610  G_loss: 1.7462\n",
      "Epoch [77/100]  D_loss: 0.7676  G_loss: 1.7221\n",
      "Epoch [78/100]  D_loss: 0.7657  G_loss: 1.7518\n",
      "Epoch [79/100]  D_loss: 0.7607  G_loss: 1.7331\n",
      "Epoch [80/100]  D_loss: 0.7633  G_loss: 1.7475\n",
      "Epoch [81/100]  D_loss: 0.7640  G_loss: 1.7588\n",
      "Epoch [82/100]  D_loss: 0.7593  G_loss: 1.7389\n",
      "Epoch [83/100]  D_loss: 0.7599  G_loss: 1.7281\n",
      "Epoch [84/100]  D_loss: 0.7559  G_loss: 1.7550\n",
      "Epoch [85/100]  D_loss: 0.7581  G_loss: 1.7437\n",
      "Epoch [86/100]  D_loss: 0.7583  G_loss: 1.7435\n",
      "Epoch [87/100]  D_loss: 0.7417  G_loss: 1.7621\n",
      "Epoch [88/100]  D_loss: 0.7620  G_loss: 1.7487\n",
      "Epoch [89/100]  D_loss: 0.7602  G_loss: 1.7474\n",
      "Epoch [90/100]  D_loss: 0.7520  G_loss: 1.7494\n",
      "Epoch [91/100]  D_loss: 0.7520  G_loss: 1.7393\n",
      "Epoch [92/100]  D_loss: 0.7469  G_loss: 1.7660\n",
      "Epoch [93/100]  D_loss: 0.7590  G_loss: 1.7462\n",
      "Epoch [94/100]  D_loss: 0.7513  G_loss: 1.7472\n",
      "Epoch [95/100]  D_loss: 0.7572  G_loss: 1.7384\n",
      "Epoch [96/100]  D_loss: 0.7475  G_loss: 1.7452\n",
      "Epoch [97/100]  D_loss: 0.7559  G_loss: 1.7550\n",
      "Epoch [98/100]  D_loss: 0.7610  G_loss: 1.7305\n",
      "Epoch [99/100]  D_loss: 0.7516  G_loss: 1.7455\n",
      "Epoch [100/100]  D_loss: 0.7407  G_loss: 1.7516\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  # Use an interactive backend; change to 'Qt5Agg' or others if needed\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output  # Optional: For Jupyter environments; comment out if not in Jupyter\n",
    "\n",
    "\n",
    "d_losses, g_losses = [], []  # Lists to store losses (last batch per epoch; for averages, accumulate inside inner loop)\n",
    "\n",
    "plt.ion()  # Interactive mode on\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_d_loss = 0.0\n",
    "    epoch_g_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "        batch_size = imgs.size(0)\n",
    "        real_imgs = imgs.view(batch_size, -1).type(torch.FloatTensor)  # Add .to(device) if using GPU\n",
    "        \n",
    "        # Train D\n",
    "        z = p_z(batch_size)  # e.g., torch.randn(batch_size, latent_dim)\n",
    "        fake_imgs = G(z).detach()\n",
    "        d_loss = discriminator_loss(D, real_imgs, fake_imgs)\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train G\n",
    "        z = p_z(batch_size)\n",
    "        fake_imgs = G(z)\n",
    "        g_loss = generator_loss(D, fake_imgs, non_saturating=True)\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        epoch_d_loss += d_loss.item()\n",
    "        epoch_g_loss += g_loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    avg_d_loss = epoch_d_loss / num_batches\n",
    "    avg_g_loss = epoch_g_loss / num_batches\n",
    "    d_losses.append(avg_d_loss)\n",
    "    g_losses.append(avg_g_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}]  D_loss: {avg_d_loss:.4f}  G_loss: {avg_g_loss:.4f}\")\n",
    "\n",
    "    ax.clear()\n",
    "    ax.plot(d_losses, label=\"D loss\", color=\"blue\")\n",
    "    ax.plot(g_losses, label=\"G loss\", color=\"orange\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    fig.canvas.draw()  # Explicit redraw\n",
    "    fig.canvas.flush_events()  # Flush events\n",
    "    plt.pause(0.1)  # Pause for visibility (adjust as needed)\n",
    "\n",
    "    # Alternative for Jupyter: Use clear_output for live updates\n",
    "    # clear_output(wait=True)\n",
    "    # plt.figure()\n",
    "    # plt.plot(d_losses, label=\"D loss\", color=\"blue\")\n",
    "    # plt.plot(g_losses, label=\"G loss\", color=\"orange\")\n",
    "    # plt.xlabel(\"Epochs\")\n",
    "    # plt.ylabel(\"Loss\")\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    # Save samples (uncomment and adjust frequency)\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        with torch.no_grad():\n",
    "            z = p_z(25)  \n",
    "            fake_imgs = G(z).view(25, 1, 28, 28)  # Reshape for save_image (assuming MNIST)\n",
    "            save_image(fake_imgs, f\"./images/epoch_{epoch+1}.png\", nrow=5, normalize=True)\n",
    "\n",
    "plt.ioff()\n",
    "plt.figure()  # New figure to avoid overriding the interactive one\n",
    "plt.plot(d_losses, label=\"D loss\", color=\"blue\")\n",
    "plt.plot(g_losses, label=\"G loss\", color=\"orange\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f186637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa87d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_codes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
